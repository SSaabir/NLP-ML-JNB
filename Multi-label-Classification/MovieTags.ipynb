{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fd397c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcffdb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Imprisoned in the 1940s for the double murder ...</td>\n",
       "      <td>[18, 80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>[18, 80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>[18, 80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>[18, 36, 10752]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>The defense and the prosecution have rested an...</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  The Shawshank Redemption   \n",
       "1             The Godfather   \n",
       "2     The Godfather Part II   \n",
       "3          Schindler's List   \n",
       "4              12 Angry Men   \n",
       "\n",
       "                                            overview        genre_ids  \n",
       "0  Imprisoned in the 1940s for the double murder ...         [18, 80]  \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...         [18, 80]  \n",
       "2  In the continuing saga of the Corleone crime f...         [18, 80]  \n",
       "3  The true story of how businessman Oskar Schind...  [18, 36, 10752]  \n",
       "4  The defense and the prosecution have rested an...             [18]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_overview = pd.read_csv('./Data/movies_overview.csv')\n",
    "data_tags = pd.read_csv('./Data/movies_genres.csv')\n",
    "data_overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a9a5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{28: 'Action', 12: 'Adventure', 16: 'Animation', 35: 'Comedy', 80: 'Crime', 99: 'Documentary', 18: 'Drama', 10751: 'Family', 14: 'Fantasy', 36: 'History', 27: 'Horror', 10402: 'Music', 9648: 'Mystery', 10749: 'Romance', 878: 'Science Fiction', 10770: 'TV Movie', 53: 'Thriller', 10752: 'War', 37: 'Western'}\n"
     ]
    }
   ],
   "source": [
    "data_tags.head()\n",
    "tag_map = dict(zip(data_tags['id'], data_tags['name']))\n",
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c436bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f095273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(data_overview['genre_ids'].iloc[0], str):\n",
    "    data_overview['genre_ids'] = data_overview['genre_ids'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5497ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_names(tag_id_str):\n",
    "    return [tag_map.get(tag_id, \"UNKNOWN\") for tag_id in tag_id_str]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6964f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview['tag_names'] = data_overview['genre_ids'].apply(ids_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f19e2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb54e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview['overview'] = data_overview['overview'].apply(clean_text)\n",
    "data_overview['title'] = data_overview['title'].apply(clean_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1d433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = pd.DataFrame(mlb.fit_transform(data_overview['tag_names']), columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "064fbc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features varients\n",
    "#overview only\n",
    "x = data_overview['overview']\n",
    "#title and overview\n",
    "xt = (data_overview['title'] + ' ').str.strip() + ' ' + data_overview['overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "377b1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def train_model(x, y, data_name):\n",
    "    \n",
    "    x_temp, x_test, y_temp, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(solver='saga', max_iter=1000, n_jobs=-1)))\n",
    "    ])\n",
    "    \n",
    "    print(f\"Train set size: {len(x_train)}\")\n",
    "    print(f\"Validation set size: {len(x_val)}\")\n",
    "    print(f\"Test set size: {len(x_test)}\")  \n",
    "    print(f\"Number of classes: {len(y.columns)}\")\n",
    "\n",
    "\n",
    "    pipe.fit(x_train, y_train)\n",
    "\n",
    "    y_valid_pred = pipe.predict(x_val)\n",
    "    y_test_pred = pipe.predict(x_test)\n",
    "\n",
    "    val_micro_f1 = f1_score(y_val, y_valid_pred, average='micro')\n",
    "    val_macro_f1 = f1_score(y_val, y_valid_pred, average='macro')\n",
    "    val_hamming_loss = hamming_loss(y_val, y_valid_pred)\n",
    "\n",
    "    print(f\"Validation Micro F1: {val_micro_f1}\")\n",
    "    print(f\"Validation Macro F1: {val_macro_f1}\")\n",
    "    print(f\"Validation Hamming Loss: {val_hamming_loss}\")\n",
    "\n",
    "    test_micro_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "    test_macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "    test_hamming_loss = hamming_loss(y_test, y_test_pred)\n",
    "    print(f\"Test Micro F1: {test_micro_f1}\")\n",
    "    print(f\"Test Macro F1: {test_macro_f1}\")\n",
    "    print(f\"Test Hamming Loss: {test_hamming_loss}\")\n",
    "    \n",
    "    results.append({\n",
    "        'data': data_name,\n",
    "        'val_micro_f1': val_micro_f1,\n",
    "        'val_macro_f1': val_macro_f1,\n",
    "        'val_hamming_loss': val_hamming_loss,\n",
    "        'test_micro_f1': test_micro_f1,\n",
    "        'test_macro_f1': test_macro_f1,\n",
    "        'test_hamming_loss': test_hamming_loss\n",
    "    })\n",
    "    \n",
    "    return pipe, (x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6817874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 6387\n",
      "Validation set size: 1597\n",
      "Test set size: 1996\n",
      "Number of classes: 18\n",
      "Validation Micro F1: 0.3716971094165632\n",
      "Validation Macro F1: 0.18273811267482173\n",
      "Validation Hamming Loss: 0.12325193070340221\n",
      "Test Micro F1: 0.3874404261283992\n",
      "Test Macro F1: 0.19566661015775558\n",
      "Test Hamming Loss: 0.12163215319527945\n",
      "Train set size: 6387\n",
      "Validation set size: 1597\n",
      "Test set size: 1996\n",
      "Number of classes: 18\n",
      "Validation Micro F1: 0.3878809230227233\n",
      "Validation Macro F1: 0.1972600435663337\n",
      "Validation Hamming Loss: 0.12088638419258331\n",
      "Test Micro F1: 0.3989934293303509\n",
      "Test Macro F1: 0.20616781041258062\n",
      "Test Hamming Loss: 0.1196559786239145\n"
     ]
    }
   ],
   "source": [
    "pipe_overview, data_overview_split = train_model(x, y, 'overview')\n",
    "pipe_title_overview, data_title_overview_split = train_model(xt, y, 'title + overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19ee5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_results(results, pipe_overview, pipe_title_overview, data_overview_split, data_title_overview_split):\n",
    "    res = pd.DataFrame(results)\n",
    "    \n",
    "    #best pipeline (choose by val_micro_f1)\n",
    "    best_idx = res['val_micro_f1'].idxmax()\n",
    "    best_res = res.loc[best_idx, 'data']\n",
    "    print('Best data by val_micro_f1:', best_res)\n",
    "    if best_res == 'overview_only':\n",
    "        chosen_pipe = pipe_overview\n",
    "        chosen_split = data_overview_split\n",
    "    else:\n",
    "        chosen_pipe = pipe_title_overview\n",
    "        chosen_split = data_title_overview_split\n",
    "\n",
    "    \n",
    "    # Dataset imbalance check (label frequencies)\n",
    "    label_counts = y.sum().sort_values(ascending=False)\n",
    "    print('\\nTop label frequencies:\\n', label_counts.head(10))\n",
    "    print('\\nBottom label frequencies:\\n', label_counts.tail(10))\n",
    "        \n",
    "    # Verify every label appears in train and test for the chosen splits\n",
    "    X_val, X_test, _, y_val, _, y_test = chosen_split\n",
    "    missing_in_val = [c for c in y.columns if y_val[c].sum() == 0]\n",
    "    missing_in_test = [c for c in y.columns if y_test[c].sum() == 0]\n",
    "    print('Missing labels in val:', missing_in_val)\n",
    "    print('Missing labels in test:', missing_in_test)\n",
    "    \n",
    "    #reports \n",
    "    res.to_csv('./results.csv', index=False)\n",
    "    pd.DataFrame([{\n",
    "        'n_samples': len(data_overview),\n",
    "        'n_labels': len(mlb.classes_)\n",
    "    }]).to_csv('./report.txt', index=False)\n",
    "\n",
    "\n",
    "    label_counts.to_csv('./label_counts.csv')\n",
    "    \n",
    "    joblib.dump(chosen_pipe, './best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "897e57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best data by val_micro_f1: title + overview\n",
      "\n",
      "Top label frequencies:\n",
      " Drama              4523\n",
      "Comedy             3626\n",
      "Thriller           2757\n",
      "Action             2349\n",
      "Adventure          1700\n",
      "Romance            1699\n",
      "Crime              1573\n",
      "Horror             1475\n",
      "Science Fiction    1235\n",
      "Fantasy            1154\n",
      "dtype: int64\n",
      "\n",
      "Bottom label frequencies:\n",
      " Science Fiction    1235\n",
      "Fantasy            1154\n",
      "Family             1134\n",
      "Mystery             966\n",
      "Animation           910\n",
      "History             490\n",
      "War                 324\n",
      "Music               279\n",
      "Western             152\n",
      "TV Movie            119\n",
      "dtype: int64\n",
      "Missing labels in val: []\n",
      "Missing labels in test: []\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "review_results(results, pipe_overview, pipe_title_overview, data_overview_split, data_title_overview_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af241700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.multioutput import MultiOutputClassifier\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ncls = MultiOutputClassifier(RandomForestClassifier())\\ncls.fit(x_train, y_train)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cls = MultiOutputClassifier(RandomForestClassifier())\n",
    "cls.fit(x_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cc547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_valid_pred = cls.predict(x_val)\\ny_valid_pred_f = pd.DataFrame(y_valid_pred, columns=y.columns)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_valid_pred = cls.predict(x_val)\n",
    "y_valid_pred_f = pd.DataFrame(y_valid_pred, columns=y.columns)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb2b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import classification_report\\n\\nprint(\"ðŸ“Š Validation Results:\")\\nfor col in y.columns:\\n    print(f\"\\n--- {col} ---\")\\n    print(classification_report(y_val[col], y_valid_pred_f[col]))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"ðŸ“Š Validation Results:\")\n",
    "for col in y.columns:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(classification_report(y_val[col], y_valid_pred_f[col]))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b94ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_test_pred = cls.predict(x_test)\\nprint(\"ðŸ“Š Test Results:\")\\nfor col in y.columns:\\n    print(f\"\\n--- {col} ---\")\\n    print(classification_report(y_test[col], y_test_pred[:, y.columns.get_loc(col)]))\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_test_pred = cls.predict(x_test)\n",
    "print(\"ðŸ“Š Test Results:\")\n",
    "for col in y.columns:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(classification_report(y_test[col], y_test_pred[:, y.columns.get_loc(col)]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import accuracy_score\\n\\n# Label-wise exact match\\nprint(\"Exact Match Accuracy (Validation):\", accuracy_score(y_val, y_valid_pred))\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Label-wise exact match\n",
    "print(\"Exact Match Accuracy (Validation):\", accuracy_score(y_val, y_valid_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport joblib\\njoblib.dump(cls, \"multi_label_model.pkl\")\\n#Would Comments on what to do next\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "joblib.dump(cls, \"multi_label_model.pkl\")\n",
    "#Would Comments on what to do next\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
